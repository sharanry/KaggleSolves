{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline  \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# image number to output\n",
    "IMAGE_TO_DISPLAY = 20212"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data(42000,785)\n",
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0       0    ...            0         0         0         0         0   \n",
      "1       0    ...            0         0         0         0         0   \n",
      "2       0    ...            0         0         0         0         0   \n",
      "3       0    ...            0         0         0         0         0   \n",
      "4       0    ...            0         0         0         0         0   \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0         0  \n",
      "1         0         0         0         0         0  \n",
      "2         0         0         0         0         0  \n",
      "3         0         0         0         0         0  \n",
      "4         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data_t = pd.read_csv('test.csv')\n",
    "\n",
    "print('data({0[0]},{0[1]})'.format(data.shape))\n",
    "print (data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images(42000,784)\n",
      "images_t(28000,784)\n"
     ]
    }
   ],
   "source": [
    "images = data.iloc[:,1:].values\n",
    "images_t = data_t.iloc[:,:].values \n",
    "images = images.astype(np.float)\n",
    "images_t = images_t.astype(np.float)\n",
    "images = np.multiply(images, 1.0 / 255.0)\n",
    "images_t = np.multiply(images_t, 1.0 / 255.0)\n",
    "print('images({0[0]},{0[1]})'.format(images.shape))\n",
    "print('images_t({0[0]},{0[1]})'.format(images_t.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3fe441af10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display image\n",
    "def display(img):\n",
    "    \n",
    "    # (784) => (28,28)\n",
    "    one_image = img.reshape(28,28)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.imshow(one_image, cmap=cm.binary)\n",
    "\n",
    "# output image     \n",
    "display(images[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n"
     ]
    }
   ],
   "source": [
    "X = images\n",
    "y = data.iloc[:,0].values\n",
    "print(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((42000, 331), 0.0011561181138151431)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=0.99,svd_solver ='auto', whiten = False)\n",
    "pca.fit(X)\n",
    "X_ = pca.transform(X)\n",
    "print(X_.shape, pca.noise_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3fbc418790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# output image\n",
    "test = pca.inverse_transform(X_[10])\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.53097495\n",
      "Iteration 2, loss = 0.28322655\n",
      "Iteration 3, loss = 0.24014520\n",
      "Iteration 4, loss = 0.21619616\n",
      "Iteration 5, loss = 0.19932294\n",
      "Iteration 6, loss = 0.18956469\n",
      "Iteration 7, loss = 0.18037583\n",
      "Iteration 8, loss = 0.17374693\n",
      "Iteration 9, loss = 0.17635411\n",
      "Iteration 10, loss = 0.17028062\n",
      "Iteration 11, loss = 0.16975902\n",
      "Iteration 12, loss = 0.16481201\n",
      "Iteration 13, loss = 0.16652783\n",
      "Iteration 14, loss = 0.15821855\n",
      "Iteration 15, loss = 0.15906673\n",
      "Iteration 16, loss = 0.15833132\n",
      "Iteration 17, loss = 0.15731730\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.52114930\n",
      "Iteration 2, loss = 0.27723775\n",
      "Iteration 3, loss = 0.23783267\n",
      "Iteration 4, loss = 0.21381275\n",
      "Iteration 5, loss = 0.19601636\n",
      "Iteration 6, loss = 0.18637006\n",
      "Iteration 7, loss = 0.17518452\n",
      "Iteration 8, loss = 0.25288974\n",
      "Iteration 9, loss = 0.17759994\n",
      "Iteration 10, loss = 0.17552935\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.60226849\n",
      "Iteration 2, loss = 0.36769850\n",
      "Iteration 3, loss = 0.33361233\n",
      "Iteration 4, loss = 0.31414920\n",
      "Iteration 5, loss = 0.30063047\n",
      "Iteration 6, loss = 0.29365145\n",
      "Iteration 7, loss = 0.28185420\n",
      "Iteration 8, loss = 0.27787808\n",
      "Iteration 9, loss = 0.28017909\n",
      "Iteration 10, loss = 0.27278596\n",
      "Iteration 11, loss = 0.27026896\n",
      "Iteration 12, loss = 0.26874610\n",
      "Iteration 13, loss = 0.26473947\n",
      "Iteration 14, loss = 0.26134814\n",
      "Iteration 15, loss = 0.25993518\n",
      "Iteration 16, loss = 0.25788364\n",
      "Iteration 17, loss = 0.25851643\n",
      "Iteration 18, loss = 0.26288637\n",
      "Iteration 19, loss = 0.25910010\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.59448473\n",
      "Iteration 2, loss = 0.36180479\n",
      "Iteration 3, loss = 0.33317718\n",
      "Iteration 4, loss = 0.31175434\n",
      "Iteration 5, loss = 0.29607978\n",
      "Iteration 6, loss = 0.28923805\n",
      "Iteration 7, loss = 0.27651365\n",
      "Iteration 8, loss = 0.37581228\n",
      "Iteration 9, loss = 0.27821855\n",
      "Iteration 10, loss = 0.27904395\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76312029\n",
      "Iteration 2, loss = 0.53832372\n",
      "Iteration 3, loss = 0.51467317\n",
      "Iteration 4, loss = 0.50083003\n",
      "Iteration 5, loss = 0.48816084\n",
      "Iteration 6, loss = 0.48176402\n",
      "Iteration 7, loss = 0.47473338\n",
      "Iteration 8, loss = 0.47137172\n",
      "Iteration 9, loss = 0.47324290\n",
      "Iteration 10, loss = 0.46829910\n",
      "Iteration 11, loss = 0.46733729\n",
      "Iteration 12, loss = 0.46578250\n",
      "Iteration 13, loss = 0.46288391\n",
      "Iteration 14, loss = 0.46112650\n",
      "Iteration 15, loss = 0.46568764\n",
      "Iteration 16, loss = 0.46151196\n",
      "Iteration 17, loss = 0.46118098\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76043366\n",
      "Iteration 2, loss = 0.54797143\n",
      "Iteration 3, loss = 0.53313287\n",
      "Iteration 4, loss = 0.52267594\n",
      "Iteration 5, loss = 0.51127467\n",
      "Iteration 6, loss = 0.50839839\n",
      "Iteration 7, loss = 0.50088092\n",
      "Iteration 8, loss = 0.55786028\n",
      "Iteration 9, loss = 0.49195359\n",
      "Iteration 10, loss = 0.50413164\n",
      "Iteration 11, loss = 0.54696779\n",
      "Iteration 12, loss = 0.48550990\n",
      "Iteration 13, loss = 0.48347778\n",
      "Iteration 14, loss = 0.48948745\n",
      "Iteration 15, loss = 0.48018246\n",
      "Iteration 16, loss = 0.48370366\n",
      "Iteration 17, loss = 0.47974817\n",
      "Iteration 18, loss = 0.62543905\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.06654581\n",
      "Iteration 2, loss = 0.83573927\n",
      "Iteration 3, loss = 0.82169308\n",
      "Iteration 4, loss = 0.81341818\n",
      "Iteration 5, loss = 0.80670569\n",
      "Iteration 6, loss = 0.80445930\n",
      "Iteration 7, loss = 0.80434118\n",
      "Iteration 8, loss = 0.80058998\n",
      "Iteration 9, loss = 0.80059799\n",
      "Iteration 10, loss = 0.80059556\n",
      "Iteration 11, loss = 0.80134086\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.06699955\n",
      "Iteration 2, loss = 0.89452909\n",
      "Iteration 3, loss = 0.88564639\n",
      "Iteration 4, loss = 0.88644278\n",
      "Iteration 5, loss = 0.88340106\n",
      "Iteration 6, loss = 0.87620431\n",
      "Iteration 7, loss = 0.87519214\n",
      "Iteration 8, loss = 0.91270230\n",
      "Iteration 9, loss = 0.87595873\n",
      "Iteration 10, loss = 0.87963682\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.75087350\n",
      "Iteration 2, loss = 1.43911106\n",
      "Iteration 3, loss = 1.42681612\n",
      "Iteration 4, loss = 1.41776720\n",
      "Iteration 5, loss = 1.41397049\n",
      "Iteration 6, loss = 1.41563852\n",
      "Iteration 7, loss = 1.41717746\n",
      "Iteration 8, loss = 1.41560551\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.75303397\n",
      "Iteration 2, loss = 1.63764283\n",
      "Iteration 3, loss = 1.64891504\n",
      "Iteration 4, loss = 1.65557333\n",
      "Iteration 5, loss = 1.65123338\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.52898421\n",
      "Iteration 2, loss = 0.20707506\n",
      "Iteration 3, loss = 0.16636404\n",
      "Iteration 4, loss = 0.15264049\n",
      "Iteration 5, loss = 0.14495359\n",
      "Iteration 6, loss = 0.14668877\n",
      "Iteration 7, loss = 0.14053274\n",
      "Iteration 8, loss = 0.13058061\n",
      "Iteration 9, loss = 0.13515124\n",
      "Iteration 10, loss = 0.13887117\n",
      "Iteration 11, loss = 0.14123839\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.52849753\n",
      "Iteration 2, loss = 0.20921509\n",
      "Iteration 3, loss = 0.17049779\n",
      "Iteration 4, loss = 0.16059614\n",
      "Iteration 5, loss = 0.13919216\n",
      "Iteration 6, loss = 0.13905053\n",
      "Iteration 7, loss = 0.12998601\n",
      "Iteration 8, loss = 0.22734132\n",
      "Iteration 9, loss = 0.14748353\n",
      "Iteration 10, loss = 0.12779392\n",
      "Iteration 11, loss = 0.12166837\n",
      "Iteration 12, loss = 0.11544066\n",
      "Iteration 13, loss = 0.12004795\n",
      "Iteration 14, loss = 0.11798562\n",
      "Iteration 15, loss = 0.12365213\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.59678059\n",
      "Iteration 2, loss = 0.28239009\n",
      "Iteration 3, loss = 0.25255222\n",
      "Iteration 4, loss = 0.23976206\n",
      "Iteration 5, loss = 0.23341016\n",
      "Iteration 6, loss = 0.23464200\n",
      "Iteration 7, loss = 0.22481001\n",
      "Iteration 8, loss = 0.22503910\n",
      "Iteration 9, loss = 0.23014373\n",
      "Iteration 10, loss = 0.22022938\n",
      "Iteration 11, loss = 0.22388843\n",
      "Iteration 12, loss = 0.22175737\n",
      "Iteration 13, loss = 0.21551263\n",
      "Iteration 14, loss = 0.21300380\n",
      "Iteration 15, loss = 0.21545609\n",
      "Iteration 16, loss = 0.21662364\n",
      "Iteration 17, loss = 0.21729959\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.59751040\n",
      "Iteration 2, loss = 0.28223000\n",
      "Iteration 3, loss = 0.25122512\n",
      "Iteration 4, loss = 0.24395547\n",
      "Iteration 5, loss = 0.22775761\n",
      "Iteration 6, loss = 0.22964384\n",
      "Iteration 7, loss = 0.22294642\n",
      "Iteration 8, loss = 0.31235247\n",
      "Iteration 9, loss = 0.22812512\n",
      "Iteration 10, loss = 0.21462628\n",
      "Iteration 11, loss = 0.21711505\n",
      "Iteration 12, loss = 0.20646063\n",
      "Iteration 13, loss = 0.20796540\n",
      "Iteration 14, loss = 0.20732949\n",
      "Iteration 15, loss = 0.21101604\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74414070\n",
      "Iteration 2, loss = 0.43902081\n",
      "Iteration 3, loss = 0.42099907\n",
      "Iteration 4, loss = 0.40884907\n",
      "Iteration 5, loss = 0.40659518\n",
      "Iteration 6, loss = 0.40441208\n",
      "Iteration 7, loss = 0.39737947\n",
      "Iteration 8, loss = 0.39604858\n",
      "Iteration 9, loss = 0.39747407\n",
      "Iteration 10, loss = 0.39455044\n",
      "Iteration 11, loss = 0.39569712\n",
      "Iteration 12, loss = 0.39225225\n",
      "Iteration 13, loss = 0.38958410\n",
      "Iteration 14, loss = 0.39124628\n",
      "Iteration 15, loss = 0.39138665\n",
      "Iteration 16, loss = 0.38740904\n",
      "Iteration 17, loss = 0.38949441\n",
      "Iteration 18, loss = 0.38996878\n",
      "Iteration 19, loss = 0.39191185\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74859672\n",
      "Iteration 2, loss = 0.45299819\n",
      "Iteration 3, loss = 0.43331035\n",
      "Iteration 4, loss = 0.42774417\n",
      "Iteration 5, loss = 0.41771318\n",
      "Iteration 6, loss = 0.42078615\n",
      "Iteration 7, loss = 0.41201278\n",
      "Iteration 8, loss = 0.47145422\n",
      "Iteration 9, loss = 0.40732142\n",
      "Iteration 10, loss = 0.41336784\n",
      "Iteration 11, loss = 0.48078964\n",
      "Iteration 12, loss = 0.39914014\n",
      "Iteration 13, loss = 0.39520852\n",
      "Iteration 14, loss = 0.39977903\n",
      "Iteration 15, loss = 0.39661439\n",
      "Iteration 16, loss = 0.40278068\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.03256270\n",
      "Iteration 2, loss = 0.72842671\n",
      "Iteration 3, loss = 0.71605976\n",
      "Iteration 4, loss = 0.70583896\n",
      "Iteration 5, loss = 0.70089054\n",
      "Iteration 6, loss = 0.69710461\n",
      "Iteration 7, loss = 0.69119378\n",
      "Iteration 8, loss = 0.69049989\n",
      "Iteration 9, loss = 0.68959520\n",
      "Iteration 10, loss = 0.68762239\n",
      "Iteration 11, loss = 0.68809120\n",
      "Iteration 12, loss = 0.68734886\n",
      "Iteration 13, loss = 0.68266751\n",
      "Iteration 14, loss = 0.68319462\n",
      "Iteration 15, loss = 0.68489453\n",
      "Iteration 16, loss = 0.67910637\n",
      "Iteration 17, loss = 0.67922110\n",
      "Iteration 18, loss = 0.68123298\n",
      "Iteration 19, loss = 0.68119380\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.03738860\n",
      "Iteration 2, loss = 0.78657867\n",
      "Iteration 3, loss = 0.77423863\n",
      "Iteration 4, loss = 0.77112283\n",
      "Iteration 5, loss = 0.76098319\n",
      "Iteration 6, loss = 0.75647871\n",
      "Iteration 7, loss = 0.75089931\n",
      "Iteration 8, loss = 0.79703258\n",
      "Iteration 9, loss = 0.74521545\n",
      "Iteration 10, loss = 0.74290892\n",
      "Iteration 11, loss = 0.79778631\n",
      "Iteration 12, loss = 0.77299448\n",
      "Iteration 13, loss = 0.73111694\n",
      "Iteration 14, loss = 0.74362174\n",
      "Iteration 15, loss = 0.72604277\n",
      "Iteration 16, loss = 0.74054241\n",
      "Iteration 17, loss = 0.73211760\n",
      "Iteration 18, loss = 0.81133651\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.70606818\n",
      "Iteration 2, loss = 1.29107590\n",
      "Iteration 3, loss = 1.27595514\n",
      "Iteration 4, loss = 1.26915038\n",
      "Iteration 5, loss = 1.26281907\n",
      "Iteration 6, loss = 1.25487968\n",
      "Iteration 7, loss = 1.25705222\n",
      "Iteration 8, loss = 1.25487547\n",
      "Iteration 9, loss = 1.25096357\n",
      "Iteration 10, loss = 1.25134376\n",
      "Iteration 11, loss = 1.25428163\n",
      "Iteration 12, loss = 1.25151715\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.71134229\n",
      "Iteration 2, loss = 1.44240372\n",
      "Iteration 3, loss = 1.45772340\n",
      "Iteration 4, loss = 1.45636028\n",
      "Iteration 5, loss = 1.44743739\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.44808204\n",
      "Iteration 2, loss = 0.26724596\n",
      "Iteration 3, loss = 0.24932442\n",
      "Iteration 4, loss = 0.24285502\n",
      "Iteration 5, loss = 0.23885296\n",
      "Iteration 6, loss = 0.23694357\n",
      "Iteration 7, loss = 0.23764532\n",
      "Iteration 8, loss = 0.23344340\n",
      "Iteration 9, loss = 0.23497239\n",
      "Iteration 10, loss = 0.23063084\n",
      "Iteration 11, loss = 0.22903097\n",
      "Iteration 12, loss = 0.22866823\n",
      "Iteration 13, loss = 0.23114679\n",
      "Iteration 14, loss = 0.23146074\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Best score: 0.961619047619\n",
      "Best parameters: {'alpha': 0.3, 'activation': 'relu', 'learning_rate_init': 0.01, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# nn = MLPClassifier(hidden_layer_sizes = (25,25,), solver='sgd', activation = 'logistic',learning_rate_init=0.01,learning_rate='invscaling')\n",
    "nn = MLPClassifier(hidden_layer_sizes=(50, 25), max_iter=200,  verbose=100, tol=1e-3, random_state=1)\n",
    "\n",
    "parameter_grid = {'alpha': [0.1,0.3,1,3,10],\n",
    "                  'activation': ['tanh','relu'],\n",
    "                  'solver': ['adam'] ,\n",
    "                  'learning_rate_init': [0.01]\n",
    "                 }\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits= 2 )\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(nn,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "\n",
    "grid_search.fit(X_, y)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.fit(X_[0:30000],y[0:30000])\n",
    "\n",
    "# train_predict = nn.predict(X_)\n",
    "\n",
    "# print(train_predict)\n",
    "\n",
    "# test_predict = nn.predict(pca.transform(images_t))\n",
    "# print(test_predict[10])\n",
    "\n",
    "# print(nn.score(X_[0:30000],y[0:30000]))\n",
    "# print(nn.score(X_[30001:41999],y[30001:41999]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = grid_search.best_estimator_\n",
    "train_predict = classifier.predict(pca.transform(images_t))\n",
    "train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output=[]\n",
    "# for i in range(1,test_predict.shape[0]+1):\n",
    "#     output.append([(i),(test_predict[i-1])])\n",
    "    \n",
    "# # print(output)\n",
    "\n",
    "# # np.insert(output,[0,0],[\"ImageId\", \"Label\"])\n",
    "# print(output)\n",
    "\n",
    "# # output.to_csv(\"trial1.csv\")delimiter=\n",
    "# np.savetxt(\"trial1.csv\",output,delimiter=',', fmt='%d', header='ImageId,Label')\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ImageId': pd.Series(range(1,len(train_predict)+1),index=list(range(len(train_predict))),dtype='int32'),\n",
    "    'Label' : pd.Series(train_predict)\n",
    "})\n",
    "df\n",
    "\n",
    "df.to_csv(\"trialNN.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 4)\n",
    "# use global min / max to ensure all weights are shown on the same scale\n",
    "vmin, vmax = nn.coefs_[0].min(), nn.coefs_[0].max()\n",
    "for coef, ax in zip(nn.coefs_[0].T, axes.ravel()):\n",
    "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.gray, vmin=.5 * vmin,\n",
    "               vmax=.5 * vmax)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
